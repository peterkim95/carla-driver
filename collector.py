#!/usr/bin/env python

# Copyright (c) 2019 Computer Vision Center (CVC) at the Universitat Autonoma de
# Barcelona (UAB).
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

import glob
import os
import sys

try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla

import pickle
import random
import argparse
import time

from util import get_current_datetime

def generate_control_dict(control):
    control_dict = {
        'steer': control.steer,
        'throttle': control.throttle,
        'brake': control.brake,
        'hand_brake': control.hand_brake,
        'reverse': control.reverse
    }
    return control_dict

def main(args):
    actor_list = []

    # In this tutorial script, we are going to add a vehicle to the simulation
    # and let it drive in autopilot. We will also create a camera attached to
    # that vehicle, and save all the images generated by the camera to disk.

    try:
        # First of all, we need to create the client that will send the requests
        # to the simulator. Here we'll assume the simulator is accepting
        # requests in the localhost at port 2000.
        client = carla.Client('localhost', 2000)
        client.set_timeout(2.0)

        # Once we have a client we can retrieve the world that is currently
        # running.
        world = client.get_world()

        original_settings = world.get_settings()
        settings = world.get_settings()

        settings.fixed_delta_seconds = 0.1 # https://carla.readthedocs.io/en/latest/adv_synchrony_timestep/#time-step-limitations
        settings.synchronous_mode = True
        world.apply_settings(settings)

        # The world contains the list blueprints that we can use for adding new
        # actors into the simulation.
        blueprint_library = world.get_blueprint_library()

        # Now let's filter all the blueprints of type 'vehicle' and choose one
        # at random.
        bp = random.choice(blueprint_library.filter('vehicle'))

        # A blueprint contains the list of attributes that define a vehicle's
        # instance, we can read them and modify some of them. For instance,
        # let's randomize its color.
        if bp.has_attribute('color'):
            color = random.choice(bp.get_attribute('color').recommended_values)
            bp.set_attribute('color', color)

        # Now we need to give an initial transform to the vehicle. We choose a
        # random transform from the list of recommended spawn points of the map.
        transform = random.choice(world.get_map().get_spawn_points())

        # So let's tell the world to spawn the vehicle.
        vehicle = world.spawn_actor(bp, transform)

        # It is important to note that the actors we create won't be destroyed
        # unless we call their "destroy" function. If we fail to call "destroy"
        # they will stay in the simulation even after we quit the Python script.
        # For that reason, we are storing all the actors we create so we can
        # destroy them afterwards.
        actor_list.append(vehicle)
        print('created my %s' % vehicle.type_id)

        # RGB Blueprint
        camera_bp = blueprint_library.find('sensor.camera.rgb')
        camera_bp.set_attribute('sensor_tick', '0.1') # take frame every 1/10 of sec i.e. 10fps
        camera_bp.set_attribute('enable_postprocess_effects', 'True')

        # Get current datetime for versioning
        current_datetime = get_current_datetime()

        # CenterRGB
        camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
        center_rgb = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)
        actor_list.append(center_rgb)
        print('created %s' % center_rgb.type_id)
        center_rgb.listen(lambda image: image.save_to_disk(f'data/{current_datetime}/CenterRGB/{image.frame:06d}.png', carla.ColorConverter.Raw))

        # LeftRGB
        camera_transform = carla.Transform(carla.Location(x=1.5, y=-0.75, z=2.4))
        left_rgb = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)
        actor_list.append(left_rgb)
        print('created %s' % left_rgb.type_id)
        left_rgb.listen(lambda image: image.save_to_disk(f'data/{current_datetime}/LeftRGB/{image.frame:06d}.png', carla.ColorConverter.Raw))

        # RightRGB
        camera_transform = carla.Transform(carla.Location(x=1.5, y=0.75, z=2.4))
        right_rgb = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)
        actor_list.append(right_rgb)
        print('created %s' % right_rgb.type_id)
        right_rgb.listen(lambda image: image.save_to_disk(f'data/{current_datetime}/RightRGB/{image.frame:06d}.png', carla.ColorConverter.Raw))

        # But the city now is probably quite empty, let's add a few more
        # vehicles.
        # transform.location += carla.Location(x=40, y=-3.2)
        # transform.rotation.yaw = -180.0
        num_of_npcs = 20
        npc_list = []
        for _ in range(num_of_npcs):
            # transform.location.x += 8.0
            npc_bp = random.choice(blueprint_library.filter('vehicle'))
            npc_transform = random.choice(world.get_map().get_spawn_points())
            # This time we are using try_spawn_actor. If the spot is already
            # occupied by another object, the function will return None.
            npc = world.try_spawn_actor(npc_bp, npc_transform)
            if npc is not None:
                actor_list.append(npc)
                npc_list.append(npc)
                npc.set_autopilot(True)
                print('created %s' % npc.type_id)

        label = {}
        for _ in range(args.frames):
            # TODO: 'remind' these guys to move!
            vehicle.set_autopilot(True)
            for a in npc_list:
                a.set_autopilot(True)

            world.tick()
            w_frame = world.get_snapshot().frame
            label[f'{w_frame:06d}'] = generate_control_dict(vehicle.get_control())
            # print("\nWorld's frame: %d" % w_frame)
            # print(vehicle.get_control())

        print('all frames collected')
        with open(f'data/{current_datetime}/label.pickle', 'wb') as f:
            pickle.dump(label, f, pickle.HIGHEST_PROTOCOL)
        print('label saved')

    finally:
        world.apply_settings(original_settings)
        print('destroying actors')
        for actor in actor_list:
            actor.destroy()
        print('done.')


if __name__ == '__main__':
    argparser = argparse.ArgumentParser()
    argparser.add_argument(
        '-r', '--split_ratio',
        default=0.8,
        type=float,
        help='train val split ratio')
    argparser.add_argument(
        '-t', '--time_to_run',
        default=5,
        type=int,
        help='time for data collection vehicle to run')
    argparser.add_argument(
        '-f', '--frames',
        default=100,
        type=int,
        help='# of frames')
    args =  argparser.parse_args()
    main(args)

